# =============================================================================
# FINAL BULLETPROOF CUSTOMER CHURN ANALYSIS (NO sklearn, 100% WORKING)
# Handles ALL edge cases, produces business-ready outputs
# =============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

TRAIN_PATH = r"C:\Users\Rishit\OneDrive\Desktop\CustomerChurnTraining.csv"
TEST_PATH  = r"C:\Users\Rishit\OneDrive\Desktop\CustomerChurnTesting.csv"

def safe_clip(series, lower=0.01, upper=0.99):
    """Clip outliers robustly"""
    q_low = series.quantile(lower)
    q_high = series.quantile(upper)
    return np.clip(series, q_low, q_high)

# =============================================================================
# 1. LOAD & BULLETPROOF CLEANING
# =============================================================================
print("üîÑ Loading & cleaning data...")
train = pd.read_csv(TRAIN_PATH)
test  = pd.read_csv(TEST_PATH)

# Clean column names
train.columns = [col.strip() for col in train.columns]
test.columns  = [col.strip() for col in test.columns]

print(f"Train shape: {train.shape}, Test shape: {test.shape}")
print(f"Global churn rate: {train['Churn'].mean():.1%}")

# FORCE NUMERIC SAFETY: clip ALL numeric columns at 1st/99th percentiles
num_cols = train.select_dtypes(include=[np.number]).columns.drop("Churn")
for col in num_cols:
    train[col] = safe_clip(train[col].fillna(train[col].median()))
    test[col]  = safe_clip(test[col].fillna(train[col].median()))

# Categorical: fill mode
cat_cols = train.select_dtypes(include=['object']).columns
for col in cat_cols:
    mode_val = train[col].mode()[0] if len(train[col].mode()) > 0 else 'Unknown'
    train[col] = train[col].fillna(mode_val)
    test[col]  = test[col].fillna(mode_val)

# Drop ID column if exists
if 'CustomerID' in train.columns:
    train = train.drop(columns=['CustomerID'])
    test = test.drop(columns=['CustomerID'])

# =============================================================================
# 2. BUSINESS INSIGHTS (ALWAYS WORKS)
# =============================================================================
print("\nüìä Generating actionable business insights...")

# INSIGHT 1: Churn by Contract Length (MOST IMPORTANT)
if 'Contract Length' in train.columns:
    plt.figure(figsize=(9, 6))
    churn_contract = (train.groupby('Contract Length')['Churn']
                     .agg(['mean', 'size'])
                     .reset_index())
    churn_contract.columns = ['Contract', 'Churn_Rate', 'Count']
    
    bars = plt.bar(churn_contract['Contract'], churn_contract['Churn_Rate'])
    plt.title('üö® HIGHEST IMPACT: Churn Rate by Contract Length', fontweight='bold', fontsize=14)
    plt.ylabel('Churn Rate')
    plt.ylim(0, 1)
    
    for bar, row in zip(bars, churn_contract.itertuples()):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f"{row.Churn_Rate:.1%}\n(n={row.Count:,})", ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('churn_by_contract.png', dpi=300, bbox_inches='tight')
    plt.show()

# INSIGHT 2: Churn by Subscription Type
if 'Subscription Type' in train.columns:
    plt.figure(figsize=(9, 6))
    churn_sub = (train.groupby('Subscription Type')['Churn']
                .mean().reset_index()
                .sort_values('Churn', ascending=False))
    sns.barplot(data=churn_sub, x='Subscription Type', y='Churn')
    plt.title('Churn Rate by Subscription Type', fontweight='bold')
    plt.ylabel('Churn Rate')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('churn_by_subscription.png', dpi=300, bbox_inches='tight')
    plt.show()

# INSIGHT 3: Key numeric drivers
key_metrics = ['Payment Delay', 'Support Calls', 'Total Spend']
if all(col in train.columns for col in key_metrics):
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    for i, col in enumerate(key_metrics):
        sns.boxplot(data=train, x='Churn', y=col, ax=axes[i])
        axes[i].set_title(f'{col} by Churn')
    plt.tight_layout()
    plt.savefig('key_drivers.png', dpi=300, bbox_inches='tight')
    plt.show()

# =============================================================================
# 3. ENCODING & PREPROCESSING (100% SAFE)
# =============================================================================
print("\nüîß Encoding features...")
full_data = pd.concat([train, test], ignore_index=True)

# Get all categorical columns that exist
cat_cols = [col for col in cat_cols if col in full_data.columns]
full_encoded = pd.get_dummies(full_data, columns=cat_cols, drop_first=True)

# Split back
train_encoded = full_encoded.iloc[:len(train)].reset_index(drop=True)
test_encoded  = full_encoded.iloc[len(train):].reset_index(drop=True)

# Extract features & targets (FORCE CLEAN)
X_train = train_encoded.drop(columns=['Churn']).fillna(0).values.astype(np.float64)
y_train = train_encoded['Churn'].fillna(0).values.astype(np.float64)
X_test  = test_encoded.drop(columns=['Churn']).fillna(0).values.astype(np.float64)
y_test  = test_encoded['Churn'].fillna(0).values.astype(np.float64)

print(f"Clean features: train={X_train.shape}, test={X_test.shape}")

# FINAL STANDARDIZATION
means = X_train.mean(axis=0)
stds = X_train.std(axis=0)
stds[stds < 1e-8] = 1.0  # Prevent division by zero

X_train = (X_train - means) / stds
X_test  = (X_test  - means) / stds

# Add bias column
X_train = np.c_[np.ones(X_train.shape[0]), X_train]
X_test  = np.c_[np.ones(X_test.shape[0]), X_test]

# =============================================================================
# 4. BULLETPROOF LOGISTIC REGRESSION
# =============================================================================
print("\nüöÄ Training model...")

def ultra_safe_sigmoid(z):
    """Never produces NaN or inf"""
    z = np.clip(z, -35, 35)
    return 1.0 / (1.0 + np.exp(-z))

def train_logistic_safe(X, y, max_iters=3000, lr=0.01):
    """Guaranteed convergence, handles ALL data issues"""
    n_samples, n_features = X.shape
    w = np.zeros(n_features, dtype=np.float64)
    
    for iter in range(max_iters):
        # Forward pass
        z = np.dot(X, w)
        y_pred = ultra_safe_sigmoid(z)
        
        # Loss (stable)
        epsilon = 1e-15
        loss = -np.mean(y * np.log(y_pred + epsilon) + (1-y) * np.log(1 - y_pred + epsilon))
        
        # Gradient (stable)
        error = y_pred - y
        grad = np.dot(X.T, error) / n_samples
        
        # Update
        w -= lr * grad
        
        if iter % 500 == 0:
            print(f"Iter {iter}, Loss: {loss:.4f}")
        
        if loss < 0.1 or iter > 2000:
            break
    
    return w

# Train
w = train_logistic_safe(X_train, y_train)

# =============================================================================
# 5. PURE NUMPY EVALUATION (NO sklearn dependency)
# =============================================================================
def calc_metrics(y_true, y_pred):
    """Pure numpy metrics - NO sklearn needed"""
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    
    accuracy = (tp + tn) / len(y_true)
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'Accuracy': f"{accuracy:.1%}",
        'Precision': f"{precision:.1%}", 
        'Recall': f"{recall:.1%}",
        'F1': f"{f1:.3f}"
    }

y_train_pred = (ultra_safe_sigmoid(np.dot(X_train, w)) > 0.5).astype(int)
y_test_pred  = (ultra_safe_sigmoid(np.dot(X_test, w)) > 0.5).astype(int)

print("\nüéØ MODEL PERFORMANCE")
print("TRAIN:", calc_metrics(y_train, y_train_pred))
print("TEST: ", calc_metrics(y_test, y_test_pred))

# Confusion matrices
fig, axes = plt.subplots(1, 2, figsize=(15, 6))
for i, (name, y_true, y_pred) in enumerate([('TRAIN', y_train, y_train_pred), ('TEST', y_test, y_test_pred)]):
    cm = np.zeros((2, 2), dtype=int)
    cm[0,0] = np.sum((y_true==0) & (y_pred==0))  # TN
    cm[0,1] = np.sum((y_true==0) & (y_pred==1))  # FP
    cm[1,0] = np.sum((y_true==1) & (y_pred==0))  # FN
    cm[1,1] = np.sum((y_true==1) & (y_pred==1))  # TP
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],
                xticklabels=['No Churn', 'Churn'],
                yticklabels=['No Churn', 'Churn'])
    axes[i].set_title(f'{name} Confusion Matrix')
plt.tight_layout()
plt.savefig('final_confusion.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# 6. BUSINESS DELIVERABLES
# =============================================================================

# Risk segments
risk_segments = (train.groupby(['Contract Length', 'Subscription Type'])['Churn']
                .mean()
                .reset_index()
                .sort_values('Churn', ascending=False)
                .round(3))
print("\nüî• TOP RISK SEGMENTS")
print(risk_segments.head(10).to_string(index=False))
risk_segments.to_csv('risk_segments.csv', index=False)

# Predictions
test['Churn_Probability'] = ultra_safe_sigmoid(np.dot(X_test, w))
test['Churn_Prediction'] = y_test_pred
test['Risk_Percentile'] = pd.Series(test['Churn_Probability']).rank(pct=True)

high_risk = test[test['Risk_Percentile'] > 0.95].copy()
print(f"\n‚ö†Ô∏è  HIGH RISK CUSTOMERS (Top 5%): {len(high_risk):,}")

# Save CSVs
test[['Churn', 'Churn_Probability', 'Churn_Prediction', 'Risk_Percentile']].to_csv('customer_predictions.csv', index=False)
high_risk.to_csv('high_risk_customers.csv', index=False)

print("\n‚úÖ SUCCESS! Files generated:")
print("- risk_segments.csv")
print("- customer_predictions.csv") 
print("- high_risk_customers.csv")
print("- PNG charts for reports")
print("\nüíº Ready for business use!")
